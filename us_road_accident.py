# -*- coding: utf-8 -*-
"""US_road_Accident.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UzblaitmtHi_qpybIGzSWd8IGUBZ-K44
"""

import kagglehub
path = kagglehub.dataset_download("sobhanmoosavi/us-accidents")
print(path)

"""## Downlaod the Data From Kaggle and Import"""

import os
os.listdir(path)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
import random

file = path + "/US_Accidents_March23.csv"

# total rows manually dekhna (colab me)
# !wc -l "/content/US_Accidents_March23.csv"

total_rows = 7600000   # approx 7.6M (aap exact count laga sakte ho)

sample_size = 500000
skip = sorted(random.sample(range(1, total_rows), total_rows - sample_size))

df = pd.read_csv(file, skiprows=skip)
df.head()

"""# US Road Accidents Exploratory Data Analysis


1.   Talk About EDA
2.   Talk about the Dataset (source, what is conatin, how     much will be useful)
"""

df.head(4)

df.shape

df.info()

df.describe()

df.columns

df.isnull().sum()

import warnings
warnings.filterwarnings("ignore")

numerics = ["int64", 'int16', 'int32','int8', 'float32', 'float64', 'float16']
numeric_df = df.select_dtypes(include = numerics)
len(numeric_df.columns)

missing_percentage = df.isnull().sum().sort_values(ascending= False)/ len(df)
missing_percentage

type(missing_percentage)

missing_percentage[missing_percentage != 0].plot(kind = 'barh')



"""## Data Prepartion & Cleaning"""

df.columns

df.City

cities = df.City.unique()
len(cities)

df.shape

cities_by_accident = df.City.value_counts()
cities_by_accident

cities_by_accident[:20]

cities_by_accident[:20].plot(kind= "bar")

sns.set_style("darkgrid")

sns.histplot(cities_by_accident, log_scale= True)

cities_by_accident[cities_by_accident == 1].value_counts()

cities_by_accident[cities_by_accident == 1]

# Start time Analysis

df.Start_Time

df.Start_Time = pd.to_datetime(df.Start_Time)

sns.distplot(df.Start_Time.dt.hour, bins=24, kde=False, norm_hist=True)

df.Source.value_counts().plot(kind='pie', autopct='%1.1f%%')



"""# Start Latitude & Longitude"""

df.Start_Lat

df.Start_Lng

sample_df = df.sample(int(0.1 * len(df)))

sns.scatterplot(x=sample_df.Start_Lng, y=sample_df.Start_Lat, size=0.001)

import folium

lat, lon = df.Start_Lat[0], df.Start_Lng[0]
lat, lon

for x in df[['Start_Lat', 'Start_Lng']].sample(100).iteritems():
  print(x[1])

"""## exploratory Analysis and Visualization"""

zip(list(df.Start_Lat), list(df.Start_Lng))

from folium.plugins import HeatMap

sample_df = df.sample(int(0.001 * len(df)))
lat_lon_pairs = list(zip(list(sample_df.Start_Lat), list(sample_df.Start_Lng)))

map = folium.Map()
HeatMap(lat_lon_pairs).add_to(map)
map

















"""## Summary & Conclusion


*   No data from New York
*   The number of accidents per city decreases exponentially

*   Less than 5% of cities have more than 1000 yearly accidents.
*   Over 1200 cities have reported just one accident (need to investigate)




"""

